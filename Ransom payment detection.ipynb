{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de8a6baf-5cc1-4eb4-893d-6b9c718b97e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "import seaborn as sns\n",
    "from pyspark.mllib.stat import Statistics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9d96e40-e292-44fc-ad0d-a98a72082bee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " raw_df = spark.read.csv(\"/mnt/team14/data/BitcoinHeistData.csv\",inferSchema=True,header=True)\n",
    "raw_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6353939a-1a59-443d-9f69-f14462cde4fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#shape of dataframe\n",
    "print(raw_df.count(),len(raw_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "583348b4-6d91-4ff1-92b3-db0417887feb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cba7b935-1c97-4c57-ba5a-dd23138bfbff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Due to the number of distinct labels, we decided to cluster the ransomware labels by Location, changing labels to 4 class problem from 29 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfead042-6d3a-4e57-9fc9-ce6b0609394a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "distinct_labels = ['padua','montreal','princeton','white']\n",
    "for i in range(len(distinct_labels)):\n",
    "  raw_df = raw_df.withColumn(\"label\", F.when(F.col(\"label\").startswith(distinct_labels[i]),distinct_labels[i]).otherwise(F.col(\"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b80361b5-bdd7-4cb9-86fa-3d231988f3c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#printing distinct lables we got in the end\n",
    "raw_df.select(\"label\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bbb9f3c-1c97-4bbf-9a4c-bce95f92291b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#copying raw_df to df\n",
    "df = raw_df\n",
    "raw_df.unpersist()\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7efb0aeb-ec87-43e4-a5da-8d671a23f716",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c0c362-898d-4dd0-aa72-e0bd895780ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Checking the data imbalance for newly obtained labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8b2b977-0f20-40d0-9c0c-ee6352cefacc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Checking for counts of data\n",
    "display(df.groupBy('label').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dab2556b-100d-4018-b325-e520aaab26ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Checking whether we have any missing/na values in our dataset that we might have to deal with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "340946e4-f370-4dc0-a29a-836036983773",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Checking for missing values\n",
    "missing_value = df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "missing_value.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b59b92-8224-43b1-83fe-ee3488001700",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "No missing values hence we do not need to do data interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4123813-9537-490f-b318-c7226ff16abd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Checking if we have any duplicated rows in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51d5c010-8805-402e-9b93-3ad58cecfb09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.toPandas().duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9064484-17bc-4a77-9508-9b8fd50dd6db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "as the returned count is zero, it is safe to say our dataset only have distinct rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94d1902d-7eab-4735-85cd-c0301008425e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52ef4782-745b-4dfa-a544-de74d8a181b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "By checking the schema of this dataset, we can see that except address every feature is numeric so we can exclude address from our model as it is not relevant to the case and can't be label encoded to be feeded to the model either.\n",
    "We also notice that our dataset is made up of continous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3efd74b3-cab3-4916-a649-88e625c31b33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21b064b6-4ff9-4bdf-afc1-b494ce99ca03",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can see the variation in feature's ranges by looking at their min-max but visualising it using boxplot gives a better overview while making it easier to read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32039501-98eb-4dd7-a7e1-946b5ce6fb81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.toPandas().boxplot(rot=90, figsize=(10,10))\n",
    "plt.title('Boxplot for each Features')\n",
    "#plt.suptitle('')\n",
    "plt.xlabel('features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fdc3f86-1ec1-45ea-ba5d-6d071c46aacc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Looking at the box plot, it can be concluded that the dataset is ridden with lots of outliers and the range of features varies in a huge scale which might result in the ML model having trouble in learning features representing this dataset correctly so we will *\"scale\"* the dataset and deal with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fbd09ff-aae5-462c-80a8-39ff7b56ed52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features = df.rdd.map(lambda row: row[1:])\n",
    "corr_mat=Statistics.corr(features, method=\"pearson\")\n",
    "matrix = np.triu(corr_mat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15)) \n",
    "sns.heatmap(corr_mat, annot=True, xticklabels=df.columns[1:-1], yticklabels=df.columns[1:-1], square=True, mask=matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5f968f2-6513-4d99-a772-b23296c4cdd7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can see that count is fairly correlated with length and neighbours with weight. As we can see no feature is highly correlated amongst themselves, we can positively conclude that we dont have redundant features which might be following the same trend strictly or be highly proportional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e4c2ba0-460e-46f1-abf1-9b13bd1fa406",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42d63c81-acad-4cad-8960-dc2007f0630a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_mean = df.toPandas().iloc[:, :]\n",
    "data_mean.plot(kind='box', subplots=True, layout=(8,4), sharex=False, sharey=False, fontsize=12, figsize=(15,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fed72841-e91c-4adf-9759-3dff1be218d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "447d06f8-d28a-4617-ab27-4c1076ddc820",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.toPandas()[\"label\"].hist()\n",
    "plt.title('histogram showing distribution of labels')\n",
    "plt.xlabel('labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72b52612-5b1c-4726-bb81-ac7aaad87439",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e240ae77-c218-4c45-9f07-c941b2396b9e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70b7ed14-b82b-4f0b-be5b-1f83a8eb720c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Removing outliers using z-mean\n",
    "means = df.select([F.mean(F.col(c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "std_dev = df.select([F.stddev(F.col(c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "for column in df.columns[1:-1]:\n",
    "  cleaned_df = df.filter(F.abs(F.col(column) - means[column]) / std_dev[column] <= 3)\n",
    "cleaned_df.cache()\n",
    "df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ae4538c-8851-4377-ba3c-f2be2cfe923f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df.toPandas().boxplot(rot=90)\n",
    "plt.title('Boxplot for each Features')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d182ba9-c0bb-4e78-a93f-11174da98a12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a4edf31-0990-4a19-b061-fa76811f69c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(cleaned_df.groupBy('label').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "952bd142-602e-4cf8-9694-59e8c5d18698",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Decision Tree without Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f301a233-05a7-4168-b299-2b0746a23e04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler,StringIndexer,VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "feature_cols = cleaned_df.columns[1:]\n",
    "feature_cols.remove('label')\n",
    "train,test = cleaned_df.randomSplit([0.7,0.3],seed=7)\n",
    "vectorAssembler = VectorAssembler(inputCols=feature_cols,outputCol=\"vectorised\")\n",
    "standardScaler = StandardScaler(inputCol=\"vectorised\",outputCol=\"features\")\n",
    "label_stringIdx = StringIndexer(inputCol='label',outputCol='idxLabel')\n",
    "labelTransformer = label_stringIdx.fit(train)\n",
    "train = labelTransformer.transform(train)\n",
    "test = labelTransformer.transform(test)\n",
    "train.cache()\n",
    "test.cache()\n",
    "labelTransformer.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60a3d8ab-09df-46a0-ab1f-5b70b38f547e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='idxLabel',metricName='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5adcf24-50cb-4d4b-886d-6c565e9d0e6d",
     "showTitle": true,
     "title": "Training Decision Tree without Oversampling"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import PipelineModel\n",
    "dt_noOversample = DecisionTreeClassifier(featuresCol = 'features',labelCol = 'idxLabel')\n",
    "evaluator.setMetricName('f1')\n",
    "paramGrid_dt_noOversample = ParamGridBuilder().addGrid(dt_noOversample.maxDepth,[17,20,22])\\\n",
    "                                 .build()\n",
    "cv_dt_noOversample = CrossValidator(estimator=dt_noOversample,estimatorParamMaps=paramGrid_dt_noOversample,evaluator = evaluator,numFolds=5)\n",
    "pipeline_dt_noOversample = Pipeline(stages=[vectorAssembler,standardScaler,cv_dt_noOversample])\n",
    "# pipeline_dtModel_noOversample = pipeline_dt_noOversample.fit(train)\n",
    "pipeline_dtModel_noOversample = PipelineModel.load(\"/mnt/team14/MulticlassModel-FinalDTwithoutOversample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5fa7ccb-b8b8-4908-a17b-8c48b91a72fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prediction = pipeline_dtModel_noOversample.transform(test)\n",
    "evaluator.setMetricName('f1')\n",
    "f1_score = evaluator.evaluate(prediction)\n",
    "evaluator.setMetricName('accuracy')\n",
    "print(f'Recall for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'Recall for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'Recall for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'Recall for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'Precision for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'Precision for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'Precision for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'Precision for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'F Measure for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'F Measure for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'F Measure for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'F Measure for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(f'Accuracy: {accuracy*100}')\n",
    "print(f'F1 Score: {f1_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "967f9e76-9748-48e3-a0d7-cdbd4fb22826",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "savePipeline(pipeline_dtModel_noOversample,\"MulticlassModel-FinalDTwithoutOversample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a755cbf6-fc31-4503-9a2c-218dea08f6dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Over-sampling (SMOTE-ENN)\n",
    "###Using Pandas and Sci-kit learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "027f0b47-1faa-413e-974f-876c1d41ad01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/building-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2\n",
    "data_cols = cleaned_df.columns[:-1]\n",
    "X = cleaned_df.toPandas().filter(items = data_cols)\n",
    "Y = cleaned_df.select('label').toPandas()\n",
    "cleaned_df.unpersist()\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cc1e9b9-e41d-4428-afd0-e4209e8f9769",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "overSampler = SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='all'))\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=7,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c992408-992a-4526-be37-2571231c0857",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x_train = x_train.drop('address',axis=1)\n",
    "x_train_res, y_train_res = overSampler.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34dd3260-7298-4df9-80ea-994ae9f9c29d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "843b7b56-1495-47f6-bf33-0a51502ae0e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataframe1 = pd.DataFrame(x_train_res,columns=data_cols)\n",
    "dataframe2 = pd.DataFrame(y_train_res,columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef5f8f43-c959-4ee9-8076-3ac023747323",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_train = dataframe1.reset_index()\n",
    "y_train = dataframe2.reset_index()\n",
    "x_test = x_test.reset_index()\n",
    "y_test = y_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82ddca93-3e04-42ba-93d8-9ee573ba9e07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train = pd.concat([x_train,y_train],axis=1)\n",
    "test = pd.concat([x_test,y_test],axis=1)\n",
    "train = train.drop(train.columns[:1],axis=1)\n",
    "test = test.drop(test.columns[:1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db183e1e-968e-4a88-829b-199a38ab4b7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create PySpark DataFrame from Pandas\n",
    "train_df=spark.createDataFrame(train) \n",
    "test_df = spark.createDataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efff9b17-aaf8-4f4a-b1fd-a258fdca93a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train_df.write.format(\"csv\").save(\"/mnt/team14/data/train_data\")\n",
    "# test_df.write.format(\"csv\").save(\"/mnt/team14/data/test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "657d0919-ac39-4a91-acde-acc5665d9a80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Train Test Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f8ae2e-20be-4c3e-b9fa-ada97b1ffa9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Both the train and test data is being saved, making it easier to train model \n",
    "import pyspark.sql.functions as F\n",
    "train_df = spark.read.csv(\"/mnt/team14/data/train_data\",inferSchema=True)\n",
    "test_df = spark.read.csv(\"/mnt/team14/data/test_data\",inferSchema=True)\n",
    "column_name = ['address','year','day','length','weight','count','looped','neighbour','income','label']\n",
    "train_df = train_df.withColumnRenamed('_c0',column_name[0])\\\n",
    "                   .withColumnRenamed('_c1',column_name[1])\\\n",
    "                   .withColumnRenamed('_c2',column_name[2])\\\n",
    "                   .withColumnRenamed('_c3',column_name[3])\\\n",
    "                   .withColumnRenamed('_c4',column_name[4])\\\n",
    "                   .withColumnRenamed('_c5',column_name[5])\\\n",
    "                   .withColumnRenamed('_c6',column_name[6])\\\n",
    "                   .withColumnRenamed('_c7',column_name[7])\\\n",
    "                   .withColumnRenamed('_c8',column_name[8])\\\n",
    "                   .withColumnRenamed('_c9',column_name[9])\n",
    "test_df = test_df.withColumnRenamed('_c0',column_name[0])\\\n",
    "                   .withColumnRenamed('_c1',column_name[1])\\\n",
    "                   .withColumnRenamed('_c2',column_name[2])\\\n",
    "                   .withColumnRenamed('_c3',column_name[3])\\\n",
    "                   .withColumnRenamed('_c4',column_name[4])\\\n",
    "                   .withColumnRenamed('_c5',column_name[5])\\\n",
    "                   .withColumnRenamed('_c6',column_name[6])\\\n",
    "                   .withColumnRenamed('_c7',column_name[7])\\\n",
    "                   .withColumnRenamed('_c8',column_name[8])\\\n",
    "                   .withColumnRenamed('_c9',column_name[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b56f1c1-e6b2-4d34-aa18-1b0161803281",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.orderBy(F.rand())\n",
    "test_df = test_df.orderBy(F.rand())\n",
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bdf8d4b-d175-4030-a70f-de144b3759b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Vector Assembler & Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2bcf191-8970-49a7-989a-059ae0d76a55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Vector Assembler, Scaler and create a Pipeline\n",
    "from pyspark.ml.feature import StandardScaler,StringIndexer,VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "feature_cols = train_df.columns[1:]\n",
    "feature_cols.remove('label')\n",
    "vectorAssembler = VectorAssembler(inputCols=feature_cols,outputCol=\"vectorised\")\n",
    "standardScaler = StandardScaler(inputCol=\"vectorised\",outputCol=\"features\")\n",
    "label_stringIdx = StringIndexer(inputCol='label',outputCol='idxLabel')\n",
    "labelTransformer = label_stringIdx.fit(train_df)\n",
    "train_df = labelTransformer.transform(train_df)\n",
    "test_df = labelTransformer.transform(test_df)\n",
    "labelTransformer.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e5f861f-fa95-4c10-9e5a-d4a8b152ebe9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86bcae79-772d-4c61-a847-e8e03c2e3e98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='idxLabel',metricName='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d81a9267-712a-412c-8d85-91879cab0165",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Method to Save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d30b32df-1003-4841-9003-be3fe9591ac6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def savePipeline(pipeline,name):\n",
    "  basePath = \"/mnt/team14/\"\n",
    "  pipeline.save(basePath + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5036360a-bb4c-4b38-820a-2e06ac1e4cc4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Bagging Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9707749-0369-4d57-98fd-b2943fcb08e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "def baggingMethod (train_features, weak_learner,bootstrap_size, maxIter=10):\n",
    "  models = []\n",
    "  for i in range(maxIter):\n",
    "    bag = train_features.sample(withReplacement=True,fraction=bootstrap_size)\n",
    "    weak_learner.setPredictionCol(f'prediction_{i}')\n",
    "    weak_learner.setProbabilityCol(f'prob_{i}')\n",
    "    weak_learner.setRawPredictionCol(f'raw_pred_{i}')\n",
    "    print(f'Model {i}')\n",
    "    models.append(weak_learner.fit(bag))\n",
    "  return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74e7f839-077b-4355-b8f2-1a66d4ede969",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Method to test each of the method\n",
    "def test_individual_models(test_features,models):\n",
    "  evaluator_test = MulticlassClassificationEvaluator(labelCol='idxLabel',metricName='f1')\n",
    "  for i in range(len(models)):\n",
    "    prediction = models[i].transform(test_features)\n",
    "    evaluator_test.setMetricName('f1')\n",
    "    evaluator_test.setPredictionCol(f'prediction_{i}')\n",
    "    f1 = evaluator_test.evaluate(prediction)\n",
    "    evaluator_test.setMetricName('accuracy')\n",
    "    acc = evaluator_test.evaluate(prediction)\n",
    "    print(f\"F1 Score Model {i} = {f1}\")\n",
    "    print(f\"Accuracy Score Model {i} = {acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c79d98c-fe7e-4c71-973d-4e72270aad2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Ensemble Method\n",
    "from statistics import mode\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def evaluate_ensemble(model,test_features):\n",
    "  final_evaluator = MulticlassClassificationEvaluator(predictionCol='pred',labelCol='idxLabel',metricName='f1')\n",
    "  mode_udf = F.udf(mode,DoubleType())\n",
    "  prediction = model.transform(test_features)\n",
    "  ensemble = prediction.select('address',F.array([f'prediction_{i}' for i in range(10)]).alias(\"prediction\"),\"idxLabel\")\n",
    "  majority_pred = ensemble.withColumn(\"pred\",mode_udf(\"prediction\"))\n",
    "  f1score = final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"f1\"})\n",
    "  accuracy = final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"accuracy\"})\n",
    "  print(f'Recall for White: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"recallByLabel\",final_evaluator.metricLabel: 3.0})}')\n",
    "  print(f'Recall for Princeton: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"recallByLabel\",final_evaluator.metricLabel: 0.0})}')\n",
    "  print(f'Recall for Montreal: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"recallByLabel\",final_evaluator.metricLabel: 2.0})}')\n",
    "  print(f'Recall for Padua: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"recallByLabel\",final_evaluator.metricLabel: 1.0})}')\n",
    "  print(f'Precision for White: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"precisionByLabel\",final_evaluator.metricLabel: 3.0})}')\n",
    "  print(f'Precision for Princeton: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"precisionByLabel\",final_evaluator.metricLabel: 0.0})}')\n",
    "  print(f'Precision for Montreal: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"precisionByLabel\",final_evaluator.metricLabel: 2.0})}')\n",
    "  print(f'Precision for Padua: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"precisionByLabel\",final_evaluator.metricLabel: 1.0})}')\n",
    "  print(f'F Measure for White: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"fMeasureByLabel\",final_evaluator.metricLabel: 3.0})}')\n",
    "  print(f'F Measure for Princeton: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"fMeasureByLabel\",final_evaluator.metricLabel: 0.0})}')\n",
    "  print(f'F Measure for Montreal: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"fMeasureByLabel\",final_evaluator.metricLabel: 2.0})}')\n",
    "  print(f'F Measure for Padua: {final_evaluator.evaluate(majority_pred, {final_evaluator.metricName: \"fMeasureByLabel\",final_evaluator.metricLabel: 1.0})}')\n",
    "  print(f'Accuracy: {accuracy * 100}')\n",
    "  print(f'F1 score: {f1score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeac7917-9ae8-4714-bc67-3f9ef56635ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Bagging with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f459120-bf3c-4c4b-a9c6-c5b2d5e6451e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scalerTransformer = StandardScaler(inputCol='vectorised',outputCol='features').fit(vectorAssembler.transform(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2bf610d-54c1-4bec-affe-8ef5057b83a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "Xtrain_bag = scalerTransformer.transform(vectorAssembler.transform(train_df))\n",
    "lr = LogisticRegression(featuresCol='features',labelCol='idxLabel',family='multinomial')\n",
    "models = baggingMethod(Xtrain_bag,lr,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1d23006-f0eb-4121-a674-c2939947f716",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "Xtest_bag = scalerTransformer.transform(vectorAssembler.transform(test_df))\n",
    "# pipeline_lrModel = PipelineModel(stages=models)\n",
    "# savePipeline(pipeline_lrModel,\"MulticlassModel-FinalELR\")\n",
    "pipeline_lrModel = PipelineModel.load(\"/mnt/team14/MulticlassModel-FinalELR\")\n",
    "evaluate_ensemble(pipeline_lrModel,Xtest_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "787bf802-2cf9-4b91-a637-3ceeb6d88568",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_individual_models(Xtest_bag,models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4c29c92-4d63-4d7b-b932-0a67d2b303d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Single Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed1c5cc8-2c08-4b67-9d0a-427512f18642",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import PipelineModel\n",
    "lrs = LogisticRegression(featuresCol='features',labelCol='idxLabel',family='multinomial')\n",
    "evaluator.setMetricName('f1')\n",
    "paramGrid_lrs = ParamGridBuilder().addGrid(lrs.elasticNetParam,[0,0.6,1.0])\\\n",
    "                                 .addGrid(lrs.regParam,[0.01,0.1,1.0])\\\n",
    "                                 .build()\n",
    "cv_lrs = CrossValidator(estimator=lrs,estimatorParamMaps=paramGrid_lrs,evaluator = evaluator,numFolds=5)\n",
    "# pipeline_lrs = Pipeline(stages=[vectorAssembler,standardScaler,cv_lrs])\n",
    "# pipeline_lrsModel = pipeline_lrs.fit(train_df)\n",
    "pipeline_lrsModel = PipelineModel.load(\"/mnt/team14/MulticlassModel-FinalLRS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06680b7d-b618-4d84-853a-715dbd843410",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating Logistic Regression\n",
    "prediction = pipeline_lrsModel.transform(test_df)\n",
    "evaluator.setMetricName('f1')\n",
    "f1_score = evaluator.evaluate(prediction)\n",
    "evaluator.setMetricName('accuracy')\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(f'Recall for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'Recall for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'Recall for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'Recall for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'Precision for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'Precision for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'Precision for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'Precision for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'F Measure for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'F Measure for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'F Measure for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'F Measure for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'Accuracy: {accuracy*100}')\n",
    "print(f'F1 Score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f848e6b-096a-4853-8c61-94d083221a25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Saving Single Logistic Regression\n",
    "savePipeline(pipeline_lrsModel,\"MulticlassModel-FinalLRS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a402d516-54fd-484d-aeab-1bced141456e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f5c12d-5e7a-44d2-97ca-537a03083bdc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Implementing random forest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import PipelineModel\n",
    "rf = RandomForestClassifier(featuresCol = 'features',labelCol = 'idxLabel')\n",
    "evaluator.setMetricName('f1')\n",
    "paramGrid_rf = ParamGridBuilder().addGrid(rf.numTrees,[15,17,19])\\\n",
    "                                 .addGrid(rf.maxDepth,[12,15,17])\\\n",
    "                                 .build()\n",
    "cv_rf = CrossValidator(estimator=rf,estimatorParamMaps=paramGrid_rf,evaluator = evaluator,numFolds=5)\n",
    "# pipeline_rf = Pipeline(stages=[vectorAssembler,standardScaler,cv_rf])\n",
    "#pipeline_rfModel = pipeline_rf.fit(train_df)\n",
    "pipeline_rfModel = PipelineModel.load(\"/mnt/team14/MulticlassModel-FinalRF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81a96af-f76a-4aea-b84e-11a30e2f39aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating Random Forest\n",
    "prediction = pipeline_rfModel.transform(test_df)\n",
    "evaluator.setMetricName('f1')\n",
    "f1_score = evaluator.evaluate(prediction)\n",
    "evaluator.setMetricName('accuracy')\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(f'Recall for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'Recall for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'Recall for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'Recall for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'Precision for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'Precision for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'Precision for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'Precision for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'F Measure for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'F Measure for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'F Measure for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'F Measure for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'Accuracy: {accuracy*100}')\n",
    "print(f'F1 Score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "299994af-ddfc-4930-b9bb-f235e0538431",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "savePipeline(pipeline_rfModel,\"MulticlassModel-FinalRF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b3df72-ae18-42f6-a745-3a999544b6bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d200231-fe84-4d59-9c3d-82b4d21a511e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Implementing Decision Tree\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import PipelineModel\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features',labelCol = 'idxLabel')\n",
    "evaluator.setMetricName('f1')\n",
    "paramGrid_dt = ParamGridBuilder().addGrid(dt.maxDepth,[30])\\\n",
    "                                 .addGrid(dt.maxBins,[128])\\\n",
    "                                 .build()\n",
    "cv_dt = CrossValidator(estimator=dt,estimatorParamMaps=paramGrid_dt,evaluator = evaluator,numFolds=5)\n",
    "pipeline_dt = Pipeline(stages=[vectorAssembler,standardScaler,cv_dt])\n",
    "pipeline_dtModel = pipeline_dt.fit(train_df)\n",
    "#pipeline_dtModel = PipelineModel.load(\"/mnt/team14/MulticlassModel-FinalDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24dcc250-e350-4534-88f3-e0a935a431b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating Decision Tree\n",
    "prediction = pipeline_dtModel.transform(test_df)\n",
    "evaluator.setMetricName('f1')\n",
    "f1_score = evaluator.evaluate(prediction)\n",
    "evaluator.setMetricName('accuracy')\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(f'Recall for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'Recall for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'Recall for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'Recall for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'Precision for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'Precision for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'Precision for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'Precision for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'F Measure for White: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 3.0})}')\n",
    "print(f'F Measure for Princeton: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 0.0})}')\n",
    "print(f'F Measure for Montreal: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 2.0})}')\n",
    "print(f'F Measure for Padua: {evaluator.evaluate(prediction, {evaluator.metricName: \"fMeasureByLabel\",evaluator.metricLabel: 1.0})}')\n",
    "print(f'Accuracy: {accuracy*100}')\n",
    "print(f'F1 Score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "135b30f0-e02e-490a-91d1-17dfe4e9064b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Saving Decision Tree\n",
    "savePipeline(pipeline_dtModel,\"MulticlassModel-FinalDT1withBin2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f56e6289-07ab-4051-8557-8f9bc83e8574",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cvModel = pipeline_dtModel.stages[-1]\n",
    "print(cvModel.bestModel.getMaxDepth())\n",
    "print(cvModel.bestModel.getMaxBins())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "080db1e7-b582-4e6f-a3c7-ed3334911d81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Team_14_Project",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
